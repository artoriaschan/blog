---
title: 算法与数据结构
subtitle: 递归及排序
date: 2020-04-18 00:00:00
permalink: /pages/150a79/
sidebar: auto
categories: 
  - 基础知识
tags: 
  - Algorithm
  - Data Structure
---
## 递归
`递归` 是一种应用非常广泛的算法（或者编程技巧）。之后我们要讲的很多数据结构和算法的编码实现都要用到递归，比如 `DFS 深度优先搜索` 、 `前中后序二叉树遍历` 等等。
### 递归需要满足的三个条件
那究竟什么样的问题可以用递归来解决呢？我总结了三个条件，只要同时满足以下三个条件，就可以用递归来解决。
* 1、一个问题的解可以分解为几个子问题的解
* 2、这个问题与分解之后的子问题，除了数据规模不同，求解思路完全一样  
* 3、存在递归终止条件
### 如何编写递归代码
写 `递归` 代码最关键的是 **写出递推公式，找到终止条件**，剩下将 `递推公式` 转化为代码就很简单了。注意，这里是两个步骤。

我们根据一个例子来讲解：假如这里有 `n` 个台阶，每次你可以跨 `1` 个台阶或者 `2` 个台阶，请问走这 `n` 个台阶有多少种走法？

我们仔细想下，实际上，可以根据`第一步的走法`把所有走法分为两类：
* 第一类是第一步走了 `1` 个台阶
* 另一类是第一步走了 `2` 个台阶

所以 `n` 个台阶的走法就等于先走 `1` 阶后，`n - 1` 个台阶的走法加上先走 `2` 阶后，`n - 2` 个台阶的走法。

用公式表示就是：$f(n) = f(n - 1) + f(n - 2)$ 。有了**递推公式**，递归代码基本上就完成了一半。

我们再来看下终止条件：当有一个台阶时， 我们不需要再继续递归，就只有一种走法。所以 $f(1) = 1$ 。又因为每次可以走 2 个台阶，所以 $f(2) = 2$。

我们把递归 终止条件 和刚刚得到的 递推公式 放到一起就是这样的：

$f(1) = 1$

$f(2) = 2$

$f(n) = f(n - 1) + f(n - 2)$

有了这个公式，我们转化成递归代码就简单多了。最终的递归代码是这样的：
```javascript
function f(n) {
  if(n === 1) return 1;
  if(n === 2) return 2;
  return f(n - 1) + f(n - 2)
}
```
总结一下，**写递归代码的关键就是找到如何将大问题 `分解` 为小问题的规律，并且基于此写出 `递推公式` ，然后再推敲 `终止条件` ，最后将 `递推公式` 和 `终止条件` 翻译成代码**。

另外编写递归代码的关键是：**只要遇到递归，我们就把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤**。
### 递归代码要警惕堆栈溢出
`函数调用` 会使用 `栈` 来保存临时变量。每调用一个函数，都会将临时变量封装为栈帧 `压入` 内存栈，等函数执行完成返回时，才出栈。

系统栈或者虚拟机栈空间一般都不大。如果递归求解的数据 `规模很大` ，调用层次很深，一直压入栈，就会有 `堆栈溢出` 的风险。

遇到这种情况可以使用 `尾递归` 优化。

`尾递归` 优化主要是对 `栈内存空间` 的优化, 这个优化是 $O(n)$ 到 $O(1)$ 的；至于 `时间` 的优化，其实是由于对空间的优化导致内存分配的工作减少所产生的，是一个常数优化，不会带来质的变化。

我们将上面的例子的代码改成 `尾递归` 形式：
```javascript
function f(n) {
    function cs(n, ret1, ret2) {
        // 递到底了
        if(n === 0){
            return ret1;
        }
        return cs(n - 1, ret2, ret1 + ret2);
    }
    return cs(n, 1, 1);
};
```
### 递归代码要警惕重复计算
除此之外，使用 `递归` 时还会出现 `重复计算` 的问题。

为了避免重复计算，我们可以通过一个 `数据结构` （比如散列表）来保存已经 `求解过` 的 $f(k)$ 。 

当递归调用到 $f(k)$ 时，先看下是否已经求解过了。

如果是，则直接从 `散列表` 中取值返回，不需要重复计算，这样就能避免刚讲的问题了。

按照上面的思路，我们来改造一下刚才的代码：
```javascript
function f(n) {
  if(n === 1) return 1;
  if(n === 2) return 2;
  if (hasSolvedList.has(n)) { 
    return hasSovledList.get(n); 
  }
  let ret = f(n - 1) + f(n - 2);
  hasSovledList.set(n, ret);
  return ret;
}
```
### 将递归代码改写为非递归代码
`递归` 有利有弊，利是递归代码的表达力很强，写起来非常 `简洁` ；而弊就是 `空间复杂度` 高、有 `堆栈溢出` 的风险、存在 `重复计算` 、过多的函数调用会 `耗时较多` 等问题。

我们可以将上面的例子用非递归的方式实现：
```javascript
function f(n) {
  if(n === 1) return 1;
  if(n === 2) return 2;

  let ret = 0;
  let pre = 2;
  let prepre = 1;
  for(let i = 3; i <= n; i ++) {
    ret = pre + prepre;
    prepre = pre;
    pre = ret;
  }
  return ret;
}
```
因为递归本身就是借助 `栈` 来实现的，只不过我们使用的 `栈` 是 `系统或者虚拟机` 本身提供的，我们没有感知罢了。

如果我们自己在内存堆上实现 `栈` ，手动模拟 `入栈` 、 `出栈` 过程，这样任何递归代码都可以改写成看上去不是递归代码的样子。

但是这种思路实际上是将递归改为了 `手动` 递归，本质并没有变，而且也并没有解决前面讲到的某些问题，徒增了实现的复杂度。
## 排序
| 排序算法 | 时间复杂度 | 是否基于比较 |
| :-----: | :------: | :--------: |
| 冒泡、插入、选择 | $O(n^2)$ | ✔️ |
| 归并、快排 | $O(nlogn)$ | ✔️ |
| 桶、计数、基数 | $O(n)$ | ❌ |
### 如何分析一个排序算法
#### 1、排序算法的执行效率
* 最好情况、最坏情况、平均情况 `时间复杂度`
* `时间复杂度` 的系数、常数 、低阶
* 比较次数和交换（或移动）次数
#### 2、排序算法的内存消耗
算法的内存消耗可以通过 `空间复杂度` 来衡量，排序算法也不例外。 `原地排序算法` ，就是特指 `空间复杂度` 是 $O(1)$ 的排序算法。
#### 3、排序算法的稳定性
针对排序算法，我们还有一个重要的度量指标，**稳定性**。这个概念是说，如果待排序的序列中存在值相等的元素，经过排序之后，**相等元素之间原有的先后顺序不变**。
### 冒泡排序
冒泡排序只会操作 `相邻` 的两个数据。每次冒泡操作都会对相邻的两个元素进行比较，看是否满足大小关系要求。如果不满足就让它俩 `互换` 。
![bubble-sort](~@assets/posts/algorithm-recursion-and-sort/bubble-sort.gif)
当某次冒泡操作已经没有数据交换时，说明已经达到 完全有序，不用再继续执行后续的冒泡操作。
实现冒泡排序：
```javascript
function bubbleSort(arr) {
  const len = arr.length;
  if (len < 1) return;
  for (let i = 0; i < len; i++) {
    let flag = false; // 标志位，用于提前结束冒泡
    for (let j = 0; j < len - i - 1; j++) {
      if (arr[j] > arr[j + 1]) {
        [arr[j], arr[j + 1]] = [arr[j + 1], arr[j]];
        flag = true;
      }
    }
    if (!flag) break; // 这层遍历中未发生元素交换，冒泡结束
  }
}
```
#### 冒泡排序性能分析
冒泡的过程只涉及相邻数据的交换操作，只需要常量级的临时空间，所以它的 `空间复杂度` 为 $O(1)$ ，是一个 `原地排序` 算法。

在冒泡排序中，只有交换才可以改变两个元素的前后顺序。为了保证冒泡排序算法的稳定性，当有相邻的两个元素 `大小相等` 的时候，我们 `不做交换` ，相同大小的数据在排序前后不会改变顺序，所以冒泡排序是稳定的排序算法。

最好情况下，要排序的数据已经是有序的了，所以 `最好情况时间复杂度` 是 $O(n)$ 。

而最坏的情况是，要排序的数据刚好是 `倒序排列` 的，我们需要进行 `n` 次冒泡操作，所以 `最坏情况时间复杂度` 为 $O(n^2)$ 。

至于 `平均情况时间复杂度` ，我们这里通过 `有序度` 和 `逆序度` 两个概念来进行 `不严格` 分析。

**有序度** 是数组中具有 `有序关系` 的元素对的个数。我们把这种 `完全有序` 的数组的 `有序度` 叫作**满有序度**。满有序度的计算公式如下：

$$满有序度 = n * \frac{(n-1)}{2}$$

**逆序度** 的定义正好跟 **有序度** 相反。关于这三个概念，我们还可以得到一个公式： **逆序度 = 满有序度 - 有序度** 。那么根据这个公式套上 **满有序度** 公式我们可以得到：

$$逆序度 = n * \frac{(n-1)}{2} - 有序度$$

`冒泡排序` 包含两个操作原子， `比较` 和 `交换` 。每交换一次， `有序度` 就加 `1` 。

最坏情况下，初始状态的 `有序度` 是 $0$ ，所以要进行 $n * \frac{(n-1)}{2}$ 次交换。

最好情况下，初始状态的 `有序度` 是 $n*\frac{(n-1)}{2}$ ，就不需要进行交换。

我们可以取个中间值 $n * \frac{(n-1)}{4}$ ，来表示 `初始有序度` 既不是很高也不是很低的平均情况。

换句话说，平均情况下，需要 $n * \frac{(n-1)}{4}$ 次交换操作，比较操作肯定要比交换操作多，而复杂度的上限是 $O(n^2)$，所以 `平均情况时间复杂度` 就是 $O(n^2)$。
### 插入排序
`插入排序` 借助的 `核心思想` 是，往一个有序数组插入数据，并保持数组依旧有序。在插入之前，我们只要遍历数组，找到数据应该插入的位置将其插入即可。

在插入排序中，我们将数组中的数据分为两个区间， **已排序区间** 和 **未排序区间** 。
![insertion-sort](~@assets/posts/algorithm-recursion-and-sort/insertion-sort.gif)
初始 `已排序区间` 只有一个元素，就是数组的第一个元素。插入算法的核心思想是取 `未排序区间` 中的 `元素` ，在 `已排序区间` 中找到合适的插入位置将其 `插入` ，并保证 `已排序区间` 数据一直有序。

`插入排序` 也包含两种操作，一种是 **元素的比较** ，一种是 **元素的移动** 。

对于一个给定的初始序列，移动操作的次数总是 `固定` 的，就等于 **逆序度** 。

实现插入排序：
```javascript
function insertionSort(arr) {
  const len = arr.length;
  if (len <= 1) return;
  for (let i = 1; i < len; i++) {
    const item = arr[i];
    let j = i - 1;
    for (; j >= 0; j--) {
      if (arr[j] > item) {
        arr[j + 1] = arr[j];
      } else {
        break;
      }
    }
    arr[j + 1] = item;
  }
}
```
#### 插入排序性能分析
`插入排序` 算法的运行并不需要额外的存储空间，所以 `空间复杂度` 是 $O(1)$ ，也就是说，这是一个 `原地排序` 算法。

`插入排序` 是 `稳定` 的排序算法。

`最好情况时间复杂度` 为 $O(n)$。

`最坏情况时间复杂度` 为 $O(n^2)$ 。

在数组中插入一个数据的 `平均时间复杂度` 是 $O(n)$ 。对于 `插入排序` 来说，每次插入操作都相当于在数组中插入一个数据，循环执行 `n` 次 `插入` 操作，所以 `平均情况时间复杂度` 为 $O(n^2)$。
### 选择排序
`选择排序` 算法的实现思路有点类似 `插入排序` ，也分 `已排序区间` 和 `未排序区间` 。但是 `选择排序` 每次会从 `未排序区间` 中找到 `最小` 的元素，将其放到 `已排序区间` 的 `末尾` 。

![insertion-sort](~@assets/posts/algorithm-recursion-and-sort/select-sort.gif)

实现选择排序：
```javascript
function selectSort(arr) {
  const len = arr.length;
  if (len <= 1) return;
  for (let i = 0; i < len; i++) {
    let min = arr[i];
    let minIndex = i;
    for (let j = i + 1; j < len; j++) {
      if (min > arr[j]) {
        min = arr[j];
        minIndex = j;
      }
    }
    [arr[i], arr[minIndex]] = [arr[minIndex], arr[i]];
  }
}
```
#### 选择排序性能分析
`选择排序空间复杂度` 为 $O(1)$，是一种 `原地排序` 算法。

`选择排序` 的 `最好情况时间复杂度` 、 `最坏情况时间复杂度` 和 `平均情况时间复杂度` 都为 $O(n^2)$。

`选择排序` 是 `不稳定` 的排序算法。
### 归并排序
我们先来看 **归并排序（Merge Sort）**。

`归并排序` 的核心思想还是蛮简单的：如果要排序一个数组，我们先把数组从中间分成 `前后两部分` ，然后对前后两部分 `分别排序` ，再将排好序的两部分 `合并` 在一起，这样整个数组就都有序了。

![merge-sort](~@assets/posts/algorithm-recursion-and-sort/merge-sort.gif)

`归并排序` 使用的就是 **分治思想** 。 `分治` ，顾名思义，就是 `分而治之` ，将一个大问题分解成小的子问题来解决。

虽然在理解上 `分治` 和 `递归` 很像，并且 `分治` 算法一般都是用 `递归` 来实现的。**但分治是一种解决问题的处理思想，递归是一种编程技巧**，这两者并不冲突。

前面章节我们说过，写 `递归` 代码的技巧就是，分析得出 `递推公式` ，然后找到 `终止条件` ，最后将 `递推公式` 翻译成 `递归代码` 。

归并排序的递推公式和终止条件如下：
```
// 递推公式
mergeSort(p, r) = merge(mergeSort(p, q), mergeSort(q + 1, r));
// 终止条件
p >= r
```
根据如上的递推公式和终止条件，我们写出归并排序的代码：
```javascript
function mergeSort(arr) {
  mergeSortInternally(arr, 0, arr.length - 1);
}
function mergeSortInternally(arr, p, r) {
  if (p >= r) return;
  const q = Math.floor((p + r) / 2);
  mergeSortInternally(arr, p, q);
  mergeSortInternally(arr, q + 1, r);
  return mergeArr(arr, p, q, r);
}

function mergeArr(arr, p, q, r) {
  let i = p;
  let j = q + 1;
  let k = 0;
  const temp = [];  // 需借助临时数组
  while (i <= q && j <= r) {
    if (arr[i] <= arr[j]) {
      temp[k++] = arr[i++];
    } else {
      temp[k++] = arr[j++];
    }
  }
  if (i <= q) {
    while (i <= q) {
      temp[k++] = arr[i++];
    }
  }
  if (j <= r) {
    while (j <= r) {
      temp[k++] = arr[j++];
    }
  }
  for (let i = 0; i <= r - p; i++) 
    arr[p + i] = temp[i]; // 排序完成后将其赋值给原数组
  }
}
```
#### 归并排序的性能分析
`归并排序` 是一个 `稳定` 的排序算法。

`归并排序` 的执行效率与要排序的原始数组的有序程度无关，所以其时间复杂度是非常稳定的，不管是 `最好情况` 、 `最坏情况` ，还是 `平均情况` ， `时间复杂度` 都是 $O(nlogn)$。

递归代码的空间复杂度并不能像时间复杂度那样累加。

刚刚我们忘记了最重要的一点，那就是，尽管每次合并操作都需要申请额外的内存空间，但在合并完成之后， `临时开辟` 的内存空间就被释放掉了。

在 `任意时刻` ，CPU 只会有 `一个函数` 在执行，也就只会有一个 `临时` 的内存空间在使用。

临时内存空间最大也不会超过 $n$ 个数据的大小，所以 `空间复杂度` 是 $O(n)$。
### 快速排序
快排 利用的也是 分治思想 。乍看起来，它有点像 归并排序 ，但是思路其实完全不一样。

快排的思想是这样的：如果要排序数组中下标从 p 到 r 之间的一组数据，我们选择 p 到 r 之间的任意一个数据作为 pivot（分区点）。

我们遍历 p 到 r 之间的数据，将小于 pivot 的放到左边，将大于 pivot 的放到右边，将 pivot 放到中间。

经过这一步骤之后，数组 p 到 r 之间的数据就被分成了三个部分，前面 p 到 q - 1 之间都是小于 pivot 的，中间是 pivot，后面的 q + 1 到 r 之间是大于 pivot 的。

根据 分治 、 递归 的处理思想，我们可以用递归排序下标从 p 到 q - 1 之间的数据和下标从 q + 1 到 r 之间的数据，直到区间缩小为 1，就说明所有的数据都有序了。

![quick-sort](~@assets/posts/algorithm-recursion-and-sort/quick-sort.gif)

如果我们用递推公式来将上面的过程写出来的话，就是这样：
```
// 递推公式
quickSor(p, r) = quickSor(p, q - 1) + quickSor(q + 1, r);
// 终止条件
p >= r
```
我们根据递推公式和终止条件，写出 快速排序 的代码：
```javascript
function quickSort(arr) {
  quickSortInternally(arr, 0, arr.length - 1);
}

function quickSortInternally(arr, p, r) {
  if (p >= r) return;
  let pivot = partition(arr, p, r);
  quickSortInternally(arr, p, pivot - 1);
  quickSortInternally(arr, pivot + 1, r);
}

function partition(arr, p, r) {
  const pivot = arr[r];
  let i = p;
  for (let j = p; j < r; j++) {
    if (arr[j] < pivot) {
      [arr[i], arr[j]] = [arr[j], arr[i]];
      i++;
    }
  }
  // 将分区点放到正确的位置
  [arr[i], arr[r]] = [arr[r], arr[i]];
  return i;
}
```

`归并排序` 中有一个 `merge` 合并函数，我们这里有一个 `partition` 分区函数。

`partition` 分区函数的逻辑就是随机选择一个元素作为 `pivot` （一般情况下，可 以选择 p 到 r 区间的最后一个元素），然后对 `arr[p，r]` 分区，函数返回 `pivot` 的下标。

`快排` 和 `归并` 用的都是**分治思想**，递推公式和递归代码也非常相似，那它们的区别在哪里呢？

`归并排序` 的处理过程是 **由下到上** 的，先处理子问题，然后再 `合并` 。而 `快排` 正好相反，它的处理过程是 **由上到下** 的，先分区，然后再处理子问题。
#### 快速排序的性能分析
`快速排序` 是一个 `不稳定` 的排序算法。

`快速排序空间复杂度` 为 $O(1)$，是一种 `原地排序` 算法。

`选择排序` 的 `最好情况时间复杂度` 为 $O(nlogn)$。

`选择排序` 的 `最坏情况时间复杂度` 为 $O(n^2)$。

`选择排序` 的 `平均情况时间复杂度` 为 $O(nlogn)$。
### 桶排序
`桶排序` ，顾名思义，会用到**桶**，核心思想是将要排序的数据分到几个 `有序` 的桶里，每个桶里的数据再 `单独排序` 。
![bucket-sort](~@assets/posts/algorithm-recursion-and-sort/bucket-sort.gif)

`桶排序` 的 `时间复杂度` 为什么是 $O(n)$ 呢？我们一块儿来分析一下。

如果要排序的数据有 $n$ 个，我们把它们均匀地划分到 $m$ 个桶内，每个桶里就有 $k = \frac{n}{m}$ 个元素。

每个桶内部使用 `快速排序` ， `时间复杂度` 为 $O(k * logk)$ 。$m$ 个 `桶排序` 的 `时间复杂度` 就是 $O(m * k * logk)$，因为 $k = \frac{n}{m}$，所以整个 `桶排序` 的 `时间复杂度` 就是 $O(n*log(\frac{n}{m}))$。

当桶的个数 $m$ 接近数据个数 $n$ 时，$log(\frac{n}{m})$ 就是一个非常小的常量，这个时候 `桶排序` 的 `时间复杂度` 接近 $O(n)$。

实际上， `桶排序` 对要 `排序数据` 的要求是非常 `苛刻` 的。所以 `桶排序` 的应用没有想象中的那么广泛。

**桶排序比较适合用在外部排序中**。所谓的外部排序就是数据存储在外部磁盘中，数据量比较 大，内存有限，无法将数据全部加载到内存中。
### 计数排序
个人觉得，**计数排序其实是桶排序的一种特殊情况**。

当要排序的 `n` 个数据，所处的范围并不大的时候，比如最大值是 `k` ，我们就可以把数据划分成 `k` 个桶。每个桶内的数据值都是相同的，**省掉了桶内排序的时间**。

![counting-sort](~@assets/posts/algorithm-recursion-and-sort/counting-sort.gif)

当我们统计完每一位对应有几个元素后，怎么还原排序后的数组呢？

这里我们可以现在 `计数数组` 中 `从前向后` 依次 `累加` 当前数对应的个数。

然后 `从后向前` 依次遍历 `原数组` ，根据 `计数数组` 中的累计数来确定当前遍历元素在排序数组中的位置，并且在确定后，计数数组对应的元素累加数相应减一。

我们实现 `计数排序` 的代码：
```javascript
function countingSort(arr) {
  const len = arr.length;
  if (len <= 1) return;
  let max = arr[0];
  for (let i = 0; i < len; i++) {
    if (max < arr[i]) max = arr[i];
  }

  const counting = new Array(max + 1).fill(0);
  for (let i = 0; i < len; i++) {
    counting[arr[i]]++;
  }
  // 从前向后依次累加
  for (let i = 1; i <= max; i++) {
    counting[i] += counting[i - 1];
  }

  const temp = [];
  // 从后向前遍历原数组
  for (let i = len - 1; i >= 0; i--) {
    const index = counting[arr[i]] - 1;
    temp[index] = arr[i];
    counting[arr[i]]--;
  }

  for (let i = 0; i < len; i++) {
    arr[i] = temp[i];
  }
}
```
`计数排序` 只能用在 `数据范围不大` 的场景中，如果数据范围 `k` 比要排序的数据 `n` 大很多，就不适合用 `计数排序` 了。

而且， `计数排序` 只能给 `非负整数` 排序，如果要排序的数据是其他类型的，要将其在不改变相对大小的情况下，**转化为非负整数**。
### 基数排序
假设我们有 10 万个 `手机号码` ，希望将这 10 万个 `手机号码` 从小到大排序，你有什么比较快速的排序方法呢？

可以使用 `基数排序` 。借助 `稳定` 排序算法，这里有一个巧妙的实现思路。

我们这里也可以借助这样的处理思路，先按照 `最后一位` 来排序手机号码，然后，再按照 `倒数第二位` 重新排序，以此类推，最后按照第一位重新排序。经过 11 次排序之后，手机号码就都有序了。

![radix-sort](~@assets/posts/algorithm-recursion-and-sort/radix-sort.gif)

根据每一位来排序，我们可以用刚讲过的 `桶排序` 或者 `计数排序` ，它们的 `时间复杂度` 可以做到 $O(n)$。

如果要排序的数据有 `k` 位，那我们就需要 `k` 次 `桶排序` 或者 `计数排序` ， `总时间复杂度` 是 $O(k*n)$ 。

当 `k` 不大的时候，比如手机号码排序的例子， `k` 最大就是 `11` ，所以 `基数排序` 的 `时间复杂度` 就近似于 $O(n)$ 。

`基数排序` 对要排序的 `数据` 是有要求的，需要可以分割出 `独立的位` 来比较，而且位之间有 `递进` 的关系，如果 `a` 数据的高位比 `b` 数据大，那剩下的低位就不用比较了。

除此之外，每一位的数据范围不能太大，要可以用 `线性排序算法` 来排序，否则， `基数排序` 的 `时间复杂度` 就无法做到 $O(n)$ 了。
### 快速排序优化
![summary](~@assets/posts/algorithm-recursion-and-sort/summary.png)

我们先来看下，为什么最坏情况下 `快速排序` 的 `时间复杂度` 是 $O(n^2)$ 呢？

我们前面讲过，如果数据原来就是 `有序` 的或者 `接近有序` 的，每次 `分区点` 都选择最后一个数据，那 `快速排序` 算法就会变得非常糟糕， `时间复杂度` 就会退化为 $O(n^2)$。

实际上，这种 $O(n^2)$ `时间复杂度` 出现的主要原因还是因为我们 `分区点` 选的不够合理。

这里介绍两个比较常用、比较简单的分区算法:
#### 1、三数取中法
我们从区间的首、尾、中间，分别取出一个数，然后对比大小，取这 `3` 个数的中间值作为 `分区点` 。
#### 2、随机法
每次从要排序的区间中， `随机选择` 一个元素作为 `分区点` 。